package com.datumbox.framework.applications.nlp;
import com.datumbox.framework.common.Configuration;
import com.datumbox.framework.core.Datasets;
import com.datumbox.framework.core.common.dataobjects.Dataframe;
import com.datumbox.framework.core.common.dataobjects.Record;
import com.datumbox.framework.core.machinelearning.MLBuilder;
import com.datumbox.framework.core.machinelearning.classification.*;
import com.datumbox.framework.core.machinelearning.common.abstracts.featureselectors.AbstractFeatureSelector;
import com.datumbox.framework.core.machinelearning.common.abstracts.modelers.AbstractClassifier;
import com.datumbox.framework.core.machinelearning.common.abstracts.transformers.AbstractScaler;
import com.datumbox.framework.core.machinelearning.featureselection.ChisquareSelect;
import com.datumbox.framework.core.machinelearning.featureselection.MutualInformation;
import com.datumbox.framework.core.machinelearning.featureselection.TFIDF;
import com.datumbox.framework.core.machinelearning.modelselection.metrics.ClassificationMetrics;
import com.datumbox.framework.core.machinelearning.preprocessing.BinaryScaler;
import com.datumbox.framework.core.common.text.extractors.NgramsExtractor;
import com.datumbox.framework.tests.Constants;
import com.datumbox.framework.tests.abstracts.AbstractTest;
import org.junit.Test;
import java.net.URI;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import static org.junit.Assert.assertEquals;
public class TextClassifierTest extends AbstractTest {
@Test
public void testTrainAndValidateBernoulliNaiveBayes() {
logger.info("testTrainAndValidateBernoulliNaiveBayes");
BernoulliNaiveBayes.TrainingParameters mlParams = new BernoulliNaiveBayes.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.8393075950598075,
1
);
}
@Test
public void testTrainAndValidateBinarizedNaiveBayes() {
logger.info("testTrainAndValidateBinarizedNaiveBayes");
BinarizedNaiveBayes.TrainingParameters mlParams = new BinarizedNaiveBayes.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.8413587159387832,
2
);
}
@Test
public void testTrainAndValidateMaximumEntropy() {
logger.info("testTrainAndValidateMaximumEntropy");
MaximumEntropy.TrainingParameters mlParams = new MaximumEntropy.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.9411031042128604,
3
);
}
@Test
public void testTrainAndValidateMultinomialNaiveBayes() {
logger.info("testTrainAndValidateMultinomialNaiveBayes");
MultinomialNaiveBayes.TrainingParameters mlParams = new MultinomialNaiveBayes.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.8685865263692268,
4
);
}
@Test
public void testTrainAndValidateOrdinalRegression() {
logger.info("testTrainAndValidateOrdinalRegression");
OrdinalRegression.TrainingParameters mlParams = new OrdinalRegression.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
BinaryScaler.TrainingParameters nsParams = new BinaryScaler.TrainingParameters();
nsParams.setScaleResponse(false);
nsParams.setThreshold(0.0);
trainAndValidate(
mlParams,
fsParams,
nsParams,
0.9292550977944236,
5
);
}
@Test
public void testTrainAndValidateSoftMaxRegression() {
logger.info("testTrainAndValidateSoftMaxRegression");
SoftMaxRegression.TrainingParameters mlParams = new SoftMaxRegression.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
BinaryScaler.TrainingParameters nsParams = new BinaryScaler.TrainingParameters();
nsParams.setScaleResponse(false);
nsParams.setThreshold(0.0);
trainAndValidate(
mlParams,
fsParams,
nsParams,
0.8979999999999999,
6
);
}
@Test
public void testTrainAndValidateSupportVectorMachine() {
logger.info("testTrainAndValidateSupportVectorMachine");
SupportVectorMachine.TrainingParameters mlParams = new SupportVectorMachine.TrainingParameters();
ChisquareSelect.TrainingParameters fsParams = new ChisquareSelect.TrainingParameters();
fsParams.setALevel(0.05);
fsParams.setMaxFeatures(1000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.9803846153846154,
7
);
}
@Test
public void testTrainAndValidateMutualInformation() {
logger.info("testTrainAndValidateMutualInformation");
MultinomialNaiveBayes.TrainingParameters mlParams = new MultinomialNaiveBayes.TrainingParameters();
MutualInformation.TrainingParameters fsParams = new MutualInformation.TrainingParameters();
fsParams.setMaxFeatures(10000);
fsParams.setRareFeatureThreshold(3);
trainAndValidate(
mlParams,
fsParams,
null,
0.91926983796055,
8
);
}
@Test
public void testTrainAndValidateTFIDF() {
logger.info("testTrainAndValidateTFIDF");
MultinomialNaiveBayes.TrainingParameters mlParams = new MultinomialNaiveBayes.TrainingParameters();
TFIDF.TrainingParameters fsParams = new TFIDF.TrainingParameters();
fsParams.setMaxFeatures(1000);
trainAndValidate(
mlParams,
fsParams,
null,
0.80461962936161,
9
);
}
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector, NS extends AbstractScaler> void trainAndValidate(
ML.AbstractTrainingParameters modelerTrainingParameters,
FS.AbstractTrainingParameters featureSelectorTrainingParameters,
NS.AbstractTrainingParameters numericalScalerTrainingParameters,
double expectedF1score,
int testId) {
Configuration configuration = getConfiguration();
String storageName = this.getClass().getSimpleName() + testId;
Map<Object, URI> dataset = Datasets.sentimentAnalysis();
TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
trainingParameters.setNumericalScalerTrainingParameters(numericalScalerTrainingParameters);
trainingParameters.setFeatureSelectorTrainingParametersList(Arrays.asList(featureSelectorTrainingParameters));
trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
exParams.setMaxDistanceBetweenKwds(2);
exParams.setExaminationWindowLength(6);
trainingParameters.setTextExtractorParameters(exParams);
TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
instance.fit(dataset);
instance.save(storageName);
ClassificationMetrics vm = instance.validate(dataset);
assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
instance.close();
instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
Dataframe validationData = instance.predict(Datasets.sentimentAnalysisUnlabeled());
List<Object> expResult = Arrays.asList("negative","positive");
int i = 0;
for(Record r : validationData.values()) {
assertEquals(expResult.get(i), r.getYPredicted());
++i;
}
instance.delete();
validationData.close();
}
}
