package com.datumbox.framework.core.machinelearning.common.abstracts.featureselectors;
import com.datumbox.framework.common.Configuration;
import com.datumbox.framework.core.common.dataobjects.Dataframe;
import com.datumbox.framework.core.common.dataobjects.Record;
import com.datumbox.framework.common.dataobjects.TypeInference;
import com.datumbox.framework.common.storage.interfaces.StorageEngine;
import com.datumbox.framework.core.machinelearning.common.abstracts.AbstractTrainer;
import java.util.*;
public abstract class AbstractCountBasedFeatureSelector<MP extends AbstractCountBasedFeatureSelector.AbstractModelParameters, TP extends AbstractCountBasedFeatureSelector.AbstractTrainingParameters> extends AbstractScoreBasedFeatureSelector<MP, TP> {
protected AbstractCountBasedFeatureSelector(TP trainingParameters, Configuration configuration) {
super(trainingParameters, configuration);
}
protected AbstractCountBasedFeatureSelector(String storageName, Configuration configuration) {
super(storageName, configuration);
}
@Override
protected void _fit(Dataframe trainingData) {
StorageEngine storageEngine = knowledgeBase.getStorageEngine();
TP trainingParameters = knowledgeBase.getTrainingParameters();
MP modelParameters = knowledgeBase.getModelParameters();
Set<TypeInference.DataType> supportedXDataTypes = getSupportedXDataTypes();
Map<Object, TypeInference.DataType> xDataTypes = trainingData.getXDataTypes();
Map<Object, Integer> tmp_classCounts = new HashMap<>(); 
Map<List<Object>, Integer> tmp_featureClassCounts = storageEngine.getBigMap("tmp_featureClassCounts", (Class<List<Object>>)(Class<?>)List.class, Integer.class, StorageEngine.MapType.HASHMAP, StorageEngine.StorageHint.IN_MEMORY, false, true); 
Map<Object, Double> tmp_featureCounts = storageEngine.getBigMap("tmp_featureCounts", Object.class, Double.class, StorageEngine.MapType.HASHMAP, StorageEngine.StorageHint.IN_MEMORY, false, true); 
logger.debug("Estimating featureCounts");
for(Record r : trainingData) {
for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
Object column = entry.getKey();
if(!supportedXDataTypes.contains(xDataTypes.get(column))) {
continue;
}
Double value = TypeInference.toDouble(entry.getValue());
if(value>0.0) {
double featureCounter = tmp_featureCounts.getOrDefault(column, 0.0);
tmp_featureCounts.put(column, ++featureCounter);
}
}
}
Integer rareFeatureThreshold = trainingParameters.getRareFeatureThreshold();
if(rareFeatureThreshold != null && rareFeatureThreshold>0) {
removeRareFeatures(tmp_featureCounts, rareFeatureThreshold);
}
logger.debug("Estimating classCounts and featureClassCounts");
for(Record r : trainingData) {
Object theClass = r.getY();
Integer classCounter = tmp_classCounts.getOrDefault(theClass, 0);
tmp_classCounts.put(theClass, ++classCounter);
for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
Object column = entry.getKey();
if(!supportedXDataTypes.contains(xDataTypes.get(column))) {
continue;
}
Double value = TypeInference.toDouble(entry.getValue());
if(value>0.0) {
List<Object> featureClassTuple = Arrays.asList(column, theClass);
Integer featureClassCounter = tmp_featureClassCounts.getOrDefault(featureClassTuple, 0);
tmp_featureClassCounts.put(featureClassTuple, ++featureClassCounter);
}
}
}
final Map<Object, Double> featureScores = modelParameters.getFeatureScores();
estimateFeatureScores(featureScores, trainingData.size(), tmp_classCounts, tmp_featureClassCounts, tmp_featureCounts);
tmp_classCounts.clear();
storageEngine.dropBigMap("tmp_featureClassCounts", tmp_featureClassCounts);
storageEngine.dropBigMap("tmp_featureCounts", tmp_featureCounts);
Integer maxFeatures = trainingParameters.getMaxFeatures();
if(maxFeatures != null && maxFeatures<featureScores.size()) {
keepTopFeatures(featureScores, maxFeatures);
}
}
@Override
protected Set<TypeInference.DataType> getSupportedXDataTypes() {
return new HashSet<>(Arrays.asList(TypeInference.DataType.BOOLEAN, TypeInference.DataType.NUMERICAL));
}
@Override
protected Set<TypeInference.DataType> getSupportedYDataTypes() {
return new HashSet<>(Arrays.asList(TypeInference.DataType.BOOLEAN, TypeInference.DataType.CATEGORICAL, TypeInference.DataType.ORDINAL));
}
protected abstract void estimateFeatureScores(Map<Object, Double> featureScores, int N, Map<Object, Integer> classCounts, Map<List<Object>, Integer> featureClassCounts, Map<Object, Double> featureCounts);
}
