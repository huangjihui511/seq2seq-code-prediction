package com.datumbox.framework.core.common.dataobjects;
import com.datumbox.framework.common.dataobjects.TypeInference;
import com.datumbox.framework.common.storage.interfaces.StorageEngine;
import com.datumbox.framework.common.utilities.RandomGenerator;
import org.apache.commons.math3.linear.OpenMapRealVector;
import org.apache.commons.math3.linear.RealMatrix;
import org.apache.commons.math3.linear.RealVector;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
Matrix representation. Some of the methods on framework require working with
matrices and this class provides the tools to achieve the necessary conversions.
public class DataframeMatrix {
static StorageEngine storageEngine;
static final AtomicInteger storageId = new AtomicInteger();
private final RealMatrix X;
private final RealVector Y;
public RealMatrix getX() {
return X;
}
public RealVector getY() {
return Y;
}
private DataframeMatrix(RealMatrix X, RealVector Y) {
this.Y = Y;
this.X = X;
}
private static void setStorageEngine(Dataframe dataset) {
if (storageEngine == null) {
synchronized(DataframeMatrix.class) {
if (storageEngine == null) {
String storageName = "mdf" + RandomGenerator.getThreadLocalRandomUnseeded().nextLong();
storageEngine = dataset.configuration.getStorageConfiguration().createStorageEngine(storageName);
}
}
}
}
to Matrixes. It populates the featureIdsReference map with the mappings
public static DataframeMatrix newInstance(Dataframe dataset, boolean addConstantColumn, Map<Integer, Integer> recordIdsReference, Map<Object, Integer> featureIdsReference) {
if(!featureIdsReference.isEmpty()) {
throw new IllegalArgumentException("The featureIdsReference map should be empty.");
}
setStorageEngine(dataset);
int n = dataset.size();
int d = dataset.xColumnSize();
if(addConstantColumn) {
++d;
}
DataframeMatrix m = new DataframeMatrix(new MapRealMatrix(n, d), new MapRealVector(n));
if(dataset.isEmpty()) {
return m;
}
boolean extractY=(dataset.getYDataType()== TypeInference.DataType.NUMERICAL);
int featureId=0;
if(addConstantColumn) {
for(int row=0;row<n;++row) {
m.X.setEntry(row, featureId, 1.0); 
}
featureIdsReference.put(Dataframe.COLUMN_NAME_CONSTANT, featureId);
++featureId;
}
int rowId = 0;
for(Map.Entry<Integer, Record> e : dataset.entries()) {
Integer rId = e.getKey();
Record r = e.getValue();
if(recordIdsReference != null) {
recordIdsReference.put(rId, rowId);
}
if(extractY) {
m.Y.setEntry(rowId, TypeInference.toDouble(r.getY()));
}
for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
Object feature = entry.getKey();
Integer knownFeatureId = featureIdsReference.get(feature);
if(knownFeatureId==null) {
featureIdsReference.put(feature, featureId);
knownFeatureId = featureId;
++featureId;
}
Double value = TypeInference.toDouble(entry.getValue());
if(value != null) {
m.X.setEntry(rowId, knownFeatureId, value);
}
}
++rowId;
}
return m;
}
existing mapping between feature names and column ids. Typically used
public static DataframeMatrix parseDataset(Dataframe newData, Map<Integer, Integer> recordIdsReference, Map<Object, Integer> featureIdsReference) {
if(featureIdsReference.isEmpty()) {
throw new IllegalArgumentException("The featureIdsReference map should not be empty.");
}
setStorageEngine(newData);
int n = newData.size();
int d = featureIdsReference.size();
DataframeMatrix m = new DataframeMatrix(new MapRealMatrix(n, d), new MapRealVector(n));
if(newData.isEmpty()) {
return m;
}
boolean extractY=(newData.getYDataType()==TypeInference.DataType.NUMERICAL);
boolean addConstantColumn = featureIdsReference.containsKey(Dataframe.COLUMN_NAME_CONSTANT);
int rowId = 0;
for(Map.Entry<Integer, Record> e : newData.entries()) {
Integer rId = e.getKey();
Record r = e.getValue();
if(recordIdsReference != null) {
recordIdsReference.put(rId, rowId);
}
if(extractY) {
m.Y.setEntry(rowId, TypeInference.toDouble(r.getY()));
}
if(addConstantColumn) {
m.X.setEntry(rowId, 0, 1.0); 
}
for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
Object feature = entry.getKey();
Double value = TypeInference.toDouble(entry.getValue());
if(value!=null) {
Integer featureId = featureIdsReference.get(feature);
if(featureId!=null) {
m.X.setEntry(rowId, featureId, value);
}
}
}
++rowId;
}
return m;
}
public static RealVector parseRecord(Record r, Map<Object, Integer> featureIdsReference) {
if(featureIdsReference.isEmpty()) {
throw new IllegalArgumentException("The featureIdsReference map should not be empty.");
}
int d = featureIdsReference.size();
RealVector v = (storageEngine != null)?new MapRealVector(d):new OpenMapRealVector(d);
boolean addConstantColumn = featureIdsReference.containsKey(Dataframe.COLUMN_NAME_CONSTANT);
if(addConstantColumn) {
v.setEntry(0, 1.0);  
}
for(Map.Entry<Object, Object> entry : r.getX().entrySet()) {
Object feature = entry.getKey();
Double value = TypeInference.toDouble(entry.getValue());
if(value!=null) {
Integer featureId = featureIdsReference.get(feature);
if(featureId!=null) {
v.setEntry(featureId, value);
}
}
else {
}
}
return v;
}
}
