package com.datumbox.framework.applications.nlp;
import com.datumbox.framework.common.Configuration;
import com.datumbox.framework.common.dataobjects.AssociativeArray;
import com.datumbox.framework.core.common.dataobjects.Dataframe;
import com.datumbox.framework.common.dataobjects.FlatDataCollection;
import com.datumbox.framework.core.common.dataobjects.Record;
import com.datumbox.framework.core.common.interfaces.Parameterizable;
import com.datumbox.framework.core.common.utilities.MapMethods;
import com.datumbox.framework.core.common.utilities.PHPMethods;
import com.datumbox.framework.core.common.text.StringCleaner;
import com.datumbox.framework.core.machinelearning.MLBuilder;
import com.datumbox.framework.core.machinelearning.clustering.Kmeans;
import com.datumbox.framework.core.statistics.descriptivestatistics.Descriptives;
import com.datumbox.framework.core.common.text.parsers.HTMLParser;
import java.util.*;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
public class CETR {
private static final Pattern NUMBER_OF_TAGS_PATTERN = Pattern.compile("<[^>]+?>", Pattern.DOTALL);
public static class Parameters implements Parameterizable {
private static final long serialVersionUID = 1L;
private int numberOfClusters = 2;
private int alphaWindowSizeFor2DModel = 3; 
private int smoothingAverageRadius = 2; 
public int getNumberOfClusters() {
return numberOfClusters;
}
public void setNumberOfClusters(int numberOfClusters) {
this.numberOfClusters = numberOfClusters;
}
public int getAlphaWindowSizeFor2DModel() {
return alphaWindowSizeFor2DModel;
}
public void setAlphaWindowSizeFor2DModel(int alphaWindowSizeFor2DModel) {
this.alphaWindowSizeFor2DModel = alphaWindowSizeFor2DModel;
}
public int getSmoothingAverageRadius() {
return smoothingAverageRadius;
}
public void setSmoothingAverageRadius(int smoothingAverageRadius) {
this.smoothingAverageRadius = smoothingAverageRadius;
}
}
private final Configuration configuration;
public CETR(Configuration configuration) {
this.configuration = configuration;
}
public String extract(String html, CETR.Parameters parameters) {
html = clearText(html); 
List<String> rows = extractRows(html); 
List<Integer> selectedRowIds = selectRows(rows, parameters);
StringBuilder sb = new StringBuilder(html.length());
for(Integer rowId : selectedRowIds) {
String row = rows.get(rowId);
row = StringCleaner.removeExtraSpaces(HTMLParser.extractText(row));
if(row.isEmpty()) {
continue;
}
sb.append(row).append(" ");
}
return sb.toString().trim();
}
private List<Integer> selectRows(List<String> rows, Parameters parameters) {
List<Double> TTRlist = calculateTTRlist(rows);
gaussianSmoothing(TTRlist); 
boolean use2Dmodel = (parameters.getAlphaWindowSizeFor2DModel()>0);
Dataframe dataset = new Dataframe(configuration);
if(use2Dmodel) {
List<Double> G = computeDerivatives(TTRlist, parameters.getAlphaWindowSizeFor2DModel());
gaussianSmoothing(G);
int n = TTRlist.size();
for(int i=0;i<n;++i) {
AssociativeArray xData = new AssociativeArray();
xData.put(0, TTRlist.get(i));
xData.put(1, G.get(i));
dataset.add(new Record(xData, null));
}
}
else {
int n = TTRlist.size();
for(int i=0;i<n;++i) {
AssociativeArray xData = new AssociativeArray();
xData.put(0, TTRlist.get(i));
dataset.add(new Record(xData, null));
}
}
performClustering(dataset, parameters.getNumberOfClusters());
Map<Object, Double> avgTTRscorePerCluster = new HashMap<>();
Map<Object, Integer> clusterCounts = new HashMap<>();
for(Record r : dataset) {
Integer clusterId = (Integer)r.getYPredicted();
Double ttr = r.getX().getDouble(0); 
Double previousValue = avgTTRscorePerCluster.getOrDefault(clusterId, 0.0);
Integer counter = clusterCounts.getOrDefault(clusterId, 0);
avgTTRscorePerCluster.put(clusterId, previousValue+ttr);
clusterCounts.put(clusterId, counter+1);
}
for(Map.Entry<Object, Double> entry : avgTTRscorePerCluster.entrySet()) {
Integer clusterId = (Integer)entry.getKey();
double avgTTR = entry.getValue()/clusterCounts.get(clusterId);
avgTTRscorePerCluster.put(clusterId, avgTTR);
}
Map.Entry<Object, Double> entry = MapMethods.selectMinKeyValue(avgTTRscorePerCluster);
Integer nonContentClusterId = (Integer)entry.getKey();
List<Integer> selectedRows = new ArrayList<>();
for(Map.Entry<Integer, Record> e : dataset.entries()) {
Integer rId = e.getKey();
Record r = e.getValue();
Integer clusterId = (Integer)r.getYPredicted();
if(!Objects.equals(clusterId, nonContentClusterId)) {
selectedRows.add(rId);
}
}
dataset.close();
return selectedRows;
}
private void performClustering(Dataframe dataset, int numberOfClusters) {
Kmeans.TrainingParameters param = new Kmeans.TrainingParameters();
param.setK(numberOfClusters);
param.setMaxIterations(200);
param.setInitializationMethod(Kmeans.TrainingParameters.Initialization.SET_FIRST_K); 
param.setDistanceMethod(Kmeans.TrainingParameters.Distance.EUCLIDIAN);
param.setWeighted(false);
param.setCategoricalGamaMultiplier(1.0);
Kmeans instance = MLBuilder.create(param, configuration);
instance.fit(dataset);
instance.predict(dataset);
instance.close();
}
private List<Double> calculateTTRlist(List<String> rows) {
List<Double> TTRlist = new ArrayList<>();
for(String row : rows) {
int x = countContentChars(row); 
int y = countNumberOfTags(row); 
if(y==0) {
y=1;
}
TTRlist.add(x/(double)y); 
}
return TTRlist;
}
private List<Double> movingAverageSmoothing(List<Double> list, int smoothingAverageRadius) {
int n = list.size();
List<Double> smoothedList = new ArrayList<>(n);
for(int idRow =0;idRow<n;++idRow) {
int from = Math.max(idRow-smoothingAverageRadius, 0);
int to = Math.min(idRow+smoothingAverageRadius, n);
double sum = 0.0;
for(int i = from; i<to ; ++i) {
sum+=list.get(i);
}
smoothedList.add(sum/(to-from)); 
}
return smoothedList;
}
private List<Double> gaussianSmoothing(List<Double> list) {
int n = list.size();
double std = Descriptives.std(new FlatDataCollection((List)list), false);
double variance = std*std;
int sygma = (int)Math.min(Math.ceil(std), (n-1.0)/2.0);
List<Double> gaussianKernel = new ArrayList<>(2*sygma+1);
double normalizer = 0.0;
for(int i =0;i<=2*sygma;++i) {
double value = 0.0;
for(int j=-sygma;j<=sygma;++j) {
value += Math.exp((-j*j)/(2.0*variance));
}
gaussianKernel.add(value);
normalizer += value;
}
for(int i =0;i<=2*sygma;++i) {
gaussianKernel.set(i, gaussianKernel.get(i)/normalizer);
}
List<Double> smoothedList = new ArrayList<>(n); 
for(int i=0;i<n;++i) {
double smoothedValue = 0.0;
for(int j=-sygma;j<=sygma;++j) {
int index = i-j;
if(index>=0 && index<n) {
smoothedValue+=gaussianKernel.get(j+sygma)*list.get(index);
}
}
smoothedList.add(smoothedValue);
}
return smoothedList;
}
private List<Double> computeDerivatives(List<Double> list, int alphaWindowSizeFor2DModel) {
int n = list.size();
List<Double> G = new ArrayList<>(n);
for(int i=0;i<n;++i) {
double sum = 0.0;
int counter = 0;
for(int j=0;j<alphaWindowSizeFor2DModel;++j) {
int index = i+j;
if(index>=0 && index<n) {
sum+=list.get(index);
++counter;
}
}
if(counter==0) {
counter=1;
}
double avgInWindow = sum/counter;
G.add(Math.abs(avgInWindow - list.get(i)));
}
return G;
}
private int countNumberOfTags(String text) {
Matcher m = NUMBER_OF_TAGS_PATTERN.matcher(text);
int count = 0;
while(m.find()) {
++count;
}
return count;
}
private int countContentChars(String text) {
return StringCleaner.removeExtraSpaces(HTMLParser.extractText(text)).length();
}
private List<String> extractRows(String text) {
return Arrays.asList(text.split("\n"));
}
private String clearText(String text) {
text = HTMLParser.removeNonTextTagsAndAttributes(text); 
if(PHPMethods.substr_count(text, '\n')<=1) { 
text = text.replace(">", ">\n");
}
text = text.replaceAll("[\\n\\r]+", "\n").replaceAll("(?m)^[ \t]*\r?\n", "").trim(); 
return text;
}
}
